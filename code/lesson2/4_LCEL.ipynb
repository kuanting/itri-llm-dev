{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yqXtlxBSNBFX",
        "GblY0YqGX6qG",
        "sw5gE8dYMt-Y"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Expression Language (LCEL)\n",
        "\n",
        "This example refers to [LangChain開發手冊(旗標)](https://www.tenlong.com.tw/products/9789863127918)"
      ],
      "metadata": {
        "id": "SABdXmtadliZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_openai rich --quiet"
      ],
      "metadata": {
        "id": "iKVs532fd95f",
        "collapsed": true
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "-XApyJ43zIxV"
      },
      "outputs": [],
      "source": [
        "# 匯入套件和金鑰\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from rich import print as pprint\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 簡單使用 LCEL"
      ],
      "metadata": {
        "id": "fk2dXmyCdJel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate,PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "str_parser = StrOutputParser()\n",
        "chat_model = ChatOpenAI()\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    '{city} 位於那一個國家？')\n",
        "\n"
      ],
      "metadata": {
        "id": "W_mCOdQ-N-EG"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LCEL\n",
        "chain = prompt | chat_model | str_parser"
      ],
      "metadata": {
        "id": "JvbMhW4rWKEr"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(chain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "collapsed": true,
        "id": "ndpJFYeLV5gf",
        "outputId": "30b43ede-84f0-45a3-99ba-d30da4beb5df"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mRunnableSequence\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33mfirst\u001b[0m=\u001b[1;35mChatPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'city'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "        \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "        \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\n",
              "            \u001b[1;35mHumanMessagePromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
              "                \u001b[33mprompt\u001b[0m=\u001b[1;35mPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
              "                    \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'city'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "                    \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "                    \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "                    \u001b[33mtemplate\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcity\u001b[0m\u001b[32m}\u001b[0m\u001b[32m 位於那一個國家？'\u001b[0m\n",
              "                \u001b[1m)\u001b[0m,\n",
              "                \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "            \u001b[1m)\u001b[0m\n",
              "        \u001b[1m]\u001b[0m\n",
              "    \u001b[1m)\u001b[0m,\n",
              "    \u001b[33mmiddle\u001b[0m=\u001b[1m[\u001b[0m\n",
              "        \u001b[1;35mChatOpenAI\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mclient\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mopenai.resources.chat.completions.Completions\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7a690bb26140\u001b[0m\u001b[39m>,\u001b[0m\n",
              "\u001b[39m            \u001b[0m\u001b[33masync_client\u001b[0m\u001b[39m=<openai.resources.chat.completions.AsyncCompletions object at \u001b[0m\u001b[1;36m0x7a6918fd9390\u001b[0m\u001b[39m>,\u001b[0m\n",
              "\u001b[39m            \u001b[0m\u001b[33mroot_client\u001b[0m\u001b[39m=<openai.OpenAI object at \u001b[0m\u001b[1;36m0x7a6919183dc0\u001b[0m\u001b[39m>,\u001b[0m\n",
              "\u001b[39m            \u001b[0m\u001b[33mroot_async_client\u001b[0m\u001b[39m=<openai.AsyncOpenAI object at \u001b[0m\u001b[1;36m0x7a690bb263e0\u001b[0m\u001b[1m>\u001b[0m,\n",
              "            \u001b[33mmodel_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "            \u001b[33mopenai_api_key\u001b[0m=\u001b[1;35mSecretStr\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'**********'\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "    \u001b[1m]\u001b[0m,\n",
              "    \u001b[33mlast\u001b[0m=\u001b[1;35mStrOutputParser\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RunnableSequence</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">first</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'city'</span><span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span>\n",
              "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessagePromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">prompt</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
              "                    <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'city'</span><span style=\"font-weight: bold\">]</span>,\n",
              "                    <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
              "                    <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
              "                    <span style=\"color: #808000; text-decoration-color: #808000\">template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{city} 位於那一個國家？'</span>\n",
              "                <span style=\"font-weight: bold\">)</span>,\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>\n",
              "            <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">]</span>\n",
              "    <span style=\"font-weight: bold\">)</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">middle</span>=<span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatOpenAI</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">client</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">openai.resources.chat.completions.Completions</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7a690bb26140</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">async_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.resources.chat.completions.AsyncCompletions object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7a6918fd9390</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">root_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.OpenAI object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7a6919183dc0</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">root_async_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.AsyncOpenAI object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7a690bb263e0</span><span style=\"font-weight: bold\">&gt;</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">model_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">openai_api_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SecretStr</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'**********'</span><span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">last</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StrOutputParser</span><span style=\"font-weight: bold\">()</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.invoke({\"city\":\"台北\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGFikcaYuKmx",
        "outputId": "09eae79b-1b15-47fd-e072-4d37a491dec5"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "台北市是中華民國（台灣）的首都，位於亞洲東部。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 手工串接個別物件"
      ],
      "metadata": {
        "id": "90tV6e5mMy5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = str_parser.invoke(\n",
        "    chat_model.invoke(\n",
        "        prompt.invoke({'city': '台北'})))\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnTA7QpPDgDa",
        "outputId": "03405c7e-9cea-46f5-a970-7b8bb23dd435"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "台北是台灣的首都，它位於中華民國的境內。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class make_chain:\n",
        "    def __init__(self, runnable_list):\n",
        "        self.__runnable_list = runnable_list\n",
        "    def invoke(self, arg):\n",
        "        for runnable in self.__runnable_list:\n",
        "            arg = runnable.invoke(arg)\n",
        "        return arg\n",
        "\n",
        "find_country_chain = make_chain(\n",
        "    [prompt, chat_model, str_parser]\n",
        ")\n",
        "\n",
        "find_country_chain.invoke({'city': '京都'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1CTHTPiaFvnK",
        "outputId": "edc19254-c11d-476d-b8fc-705f905d30b6"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'京都位於日本。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用 RunnableSequence 類別簡化多層函式的呼叫"
      ],
      "metadata": {
        "id": "JTBnsk8DM8JA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableSequence\n",
        "\n",
        "find_country_chain = RunnableSequence(\n",
        "    prompt,\n",
        "    chat_model,\n",
        "    str_parser\n",
        ")\n",
        "find_country_chain.invoke({'city': 'New York'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oN-RvHUgJzpK",
        "outputId": "e12fbf14-a656-4a1b-c10a-76eb27f5c0c1"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'New York 位於美國。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用 LCEL 建立兩個Chain, 有共通參數{city}\n"
      ],
      "metadata": {
        "id": "yqXtlxBSNBFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "find_country_chain = prompt | chat_model | str_parser\n",
        "find_country_chain.invoke({'city': '巴塞隆納'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "10cfHi2WLPbD",
        "outputId": "a4de9d06-c376-4e08-8fbe-601ba2e6716f"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'西班牙。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lang_template = ChatPromptTemplate.from_template('在{city}講哪一種語言？')\n",
        "find_lang_chain = lang_template | chat_model | str_parser\n",
        "find_lang_chain.invoke({'city': '開羅'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "g6I1gm0DP1uL",
        "outputId": "2fa8b35b-efe1-4507-c72e-fc36fc730eaa"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'在開羅，主要講的語言是阿拉伯語，屬於埃及的官方語言。此外，也有少數人口講英語或法語。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用 RunnableParallel 合併相同參數執行並整合2個 Runnable 物件\n",
        "\n"
      ],
      "metadata": {
        "id": "SiNc7XpyNNRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "find_country_and_lang_chain = RunnableParallel(\n",
        "    country=find_country_chain,\n",
        "    lang=find_lang_chain\n",
        ")\n",
        "find_country_and_lang_chain.invoke({'city': '開羅'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_88dpb1QrTs",
        "outputId": "fddb7c73-aeb6-4c27-e83c-be9914d45f47"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'country': '開羅位於埃及。',\n",
              " 'lang': '在開羅，人們主要講阿拉伯語。阿拉伯語是埃及的官方語言，也是最常用的語言。此外，許多居民也會說英語和法語。'}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(find_country_and_lang_chain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tkA7_-dr1vgA",
        "outputId": "97c792da-e3fb-477d-c7ce-b504c25d590c",
        "collapsed": true
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mRunnableParallel\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33msteps__\u001b[0m=\u001b[1m{\u001b[0m\n",
              "        \u001b[32m'country'\u001b[0m: \u001b[1;35mRunnableSequence\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mfirst\u001b[0m=\u001b[1;35mChatPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
              "                \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'city'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "                \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "                \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "                \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\n",
              "                    \u001b[1;35mHumanMessagePromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
              "                        \u001b[33mprompt\u001b[0m=\u001b[1;35mPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
              "                            \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'city'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "                            \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "                            \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "                            \u001b[33mtemplate\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcity\u001b[0m\u001b[32m}\u001b[0m\u001b[32m 位於那一個國家？'\u001b[0m\n",
              "                        \u001b[1m)\u001b[0m,\n",
              "                        \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "                    \u001b[1m)\u001b[0m\n",
              "                \u001b[1m]\u001b[0m\n",
              "            \u001b[1m)\u001b[0m,\n",
              "            \u001b[33mmiddle\u001b[0m=\u001b[1m[\u001b[0m\n",
              "                \u001b[1;35mChatOpenAI\u001b[0m\u001b[1m(\u001b[0m\n",
              "                    \u001b[33mclient\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mopenai.resources.chat.completions.Completions\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7a690bb26140\u001b[0m\u001b[39m>,\u001b[0m\n",
              "\u001b[39m                    \u001b[0m\u001b[33masync_client\u001b[0m\u001b[39m=<openai.resources.chat.completions.AsyncCompletions object at \u001b[0m\u001b[1;36m0x7a6918fd9390\u001b[0m\u001b[39m>,\u001b[0m\n",
              "\u001b[39m                    \u001b[0m\u001b[33mroot_client\u001b[0m\u001b[39m=<openai.OpenAI object at \u001b[0m\u001b[1;36m0x7a6919183dc0\u001b[0m\u001b[39m>,\u001b[0m\n",
              "\u001b[39m                    \u001b[0m\u001b[33mroot_async_client\u001b[0m\u001b[39m=<openai.AsyncOpenAI object at \u001b[0m\u001b[1;36m0x7a690bb263e0\u001b[0m\u001b[39m>,\u001b[0m\n",
              "\u001b[39m                    \u001b[0m\u001b[33mmodel_kwargs\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m                    \u001b[0m\u001b[33mopenai_api_key\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mSecretStr\u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'**********'\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39m                \u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39m            \u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m            \u001b[0m\u001b[33mlast\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mStrOutputParser\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39m        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m        \u001b[0m\u001b[32m'lang'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;35mRunnableSequence\u001b[0m\u001b[1;39m(\u001b[0m\n",
              "\u001b[39m            \u001b[0m\u001b[33mfirst\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mChatPromptTemplate\u001b[0m\u001b[1;39m(\u001b[0m\n",
              "\u001b[39m                \u001b[0m\u001b[33minput_variables\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'city'\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m                \u001b[0m\u001b[33minput_types\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m                \u001b[0m\u001b[33mpartial_variables\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m                \u001b[0m\u001b[33mmessages\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\n",
              "\u001b[39m                    \u001b[0m\u001b[1;35mHumanMessagePromptTemplate\u001b[0m\u001b[1;39m(\u001b[0m\n",
              "\u001b[39m                        \u001b[0m\u001b[33mprompt\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mPromptTemplate\u001b[0m\u001b[1;39m(\u001b[0m\n",
              "\u001b[39m                            \u001b[0m\u001b[33minput_variables\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'city'\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m                            \u001b[0m\u001b[33minput_types\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m                            \u001b[0m\u001b[33mpartial_variables\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m                            \u001b[0m\u001b[33mtemplate\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'在\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcity\u001b[0m\u001b[32m}\u001b[0m\u001b[32m講哪一種語言？'\u001b[0m\n",
              "\u001b[39m                        \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m                        \u001b[0m\u001b[33madditional_kwargs\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\n",
              "\u001b[39m                    \u001b[0m\u001b[1;39m)\u001b[0m\n",
              "\u001b[39m                \u001b[0m\u001b[1;39m]\u001b[0m\n",
              "\u001b[39m            \u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[39m            \u001b[0m\u001b[33mmiddle\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\n",
              "\u001b[39m                \u001b[0m\u001b[1;35mChatOpenAI\u001b[0m\u001b[1;39m(\u001b[0m\n",
              "\u001b[39m                    \u001b[0m\u001b[33mclient\u001b[0m\u001b[39m=<openai.resources.chat.completions.Completions object at \u001b[0m\u001b[1;36m0x7a690bb26140\u001b[0m\u001b[39m>,\u001b[0m\n",
              "\u001b[39m                    \u001b[0m\u001b[33masync_client\u001b[0m\u001b[39m=<openai.resources.chat.completions.AsyncCompletions object at \u001b[0m\u001b[1;36m0x7a6918fd9390\u001b[0m\u001b[39m>,\u001b[0m\n",
              "\u001b[39m                    \u001b[0m\u001b[33mroot_client\u001b[0m\u001b[39m=<openai.OpenAI object at \u001b[0m\u001b[1;36m0x7a6919183dc0\u001b[0m\u001b[39m>,\u001b[0m\n",
              "\u001b[39m                    \u001b[0m\u001b[33mroot_async_client\u001b[0m\u001b[39m=<openai.AsyncOpenAI object at \u001b[0m\u001b[1;36m0x7a690bb263e0\u001b[0m\u001b[1m>\u001b[0m,\n",
              "                    \u001b[33mmodel_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "                    \u001b[33mopenai_api_key\u001b[0m=\u001b[1;35mSecretStr\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'**********'\u001b[0m\u001b[1m)\u001b[0m\n",
              "                \u001b[1m)\u001b[0m\n",
              "            \u001b[1m]\u001b[0m,\n",
              "            \u001b[33mlast\u001b[0m=\u001b[1;35mStrOutputParser\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "    \u001b[1m}\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RunnableParallel</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">steps__</span>=<span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'country'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RunnableSequence</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">first</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'city'</span><span style=\"font-weight: bold\">]</span>,\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span>\n",
              "                    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessagePromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
              "                        <span style=\"color: #808000; text-decoration-color: #808000\">prompt</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
              "                            <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'city'</span><span style=\"font-weight: bold\">]</span>,\n",
              "                            <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>,\n",
              "                            <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>,\n",
              "                            <span style=\"color: #808000; text-decoration-color: #808000\">template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{city} 位於那一個國家？'</span>\n",
              "                        <span style=\"font-weight: bold\">)</span>,\n",
              "                        <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>\n",
              "                    <span style=\"font-weight: bold\">)</span>\n",
              "                <span style=\"font-weight: bold\">]</span>\n",
              "            <span style=\"font-weight: bold\">)</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">middle</span>=<span style=\"font-weight: bold\">[</span>\n",
              "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatOpenAI</span><span style=\"font-weight: bold\">(</span>\n",
              "                    <span style=\"color: #808000; text-decoration-color: #808000\">client</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">openai.resources.chat.completions.Completions</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7a690bb26140</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">async_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.resources.chat.completions.AsyncCompletions object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7a6918fd9390</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">root_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.OpenAI object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7a6919183dc0</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">root_async_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.AsyncOpenAI object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7a690bb263e0</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">model_kwargs</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">openai_api_key</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SecretStr</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'**********'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">last</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StrOutputParser</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">()</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'lang'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">RunnableSequence</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">first</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptTemplate</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'city'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">input_types</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #808000; text-decoration-color: #808000\">messages</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessagePromptTemplate</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">prompt</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'city'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">input_types</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                            </span><span style=\"color: #808000; text-decoration-color: #808000\">template</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'在{city}講哪一種語言？'</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                        </span><span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #808000; text-decoration-color: #808000\">middle</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatOpenAI</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.resources.chat.completions.Completions object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7a690bb26140</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">async_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.resources.chat.completions.AsyncCompletions object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7a6918fd9390</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">root_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.OpenAI object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7a6919183dc0</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">root_async_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;openai.AsyncOpenAI object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7a690bb263e0</span><span style=\"font-weight: bold\">&gt;</span>,\n",
              "                    <span style=\"color: #808000; text-decoration-color: #808000\">model_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
              "                    <span style=\"color: #808000; text-decoration-color: #808000\">openai_api_key</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SecretStr</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'**********'</span><span style=\"font-weight: bold\">)</span>\n",
              "                <span style=\"font-weight: bold\">)</span>\n",
              "            <span style=\"font-weight: bold\">]</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">last</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StrOutputParser</span><span style=\"font-weight: bold\">()</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_country_and_lang_chain = RunnableParallel({\n",
        "    'country': find_country_chain,\n",
        "    'lang': find_lang_chain\n",
        "})\n",
        "find_country_and_lang_chain.invoke({'city': '台南'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzJtXDlIiBeh",
        "outputId": "a89ed51f-60a5-4659-d53e-98e4c3dadcee"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'country': '台南位於台灣。',\n",
              " 'lang': '在台南主要講的語言是閩南語，此外也常使用華語（中文）。閩南語是台灣本土語言之一，廣泛在台灣南部地區使用，包括台南市。'}"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_template = ChatPromptTemplate.from_template('{country}{lang}')\n",
        "summary_chain = (\n",
        "    {\n",
        "        'country': find_country_chain,\n",
        "        'lang': find_lang_chain\n",
        "    }\n",
        "    | summary_template)\n",
        "pprint(summary_chain.invoke({'city': '釜山'}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "PklYepnkkdZe",
        "outputId": "8b33fbb7-a991-4309-c594-00aefaf1284e"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mChatPromptValue\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\n",
              "        \u001b[1;35mHumanMessage\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mcontent\u001b[0m=\u001b[32m'釜山位於南韓。在釜山，主要使用的語言是韓語。然而，由於釜山是韓國的第二大城市，也有許多人會說英\u001b[0m\n",
              "\u001b[32m語或其他外語。'\u001b[0m,\n",
              "            \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "            \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "    \u001b[1m]\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptValue</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessage</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'釜山位於南韓。在釜山，主要使用的語言是韓語。然而，由於釜山是韓國的第二大城市，也有許多人會說英</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">語或其他外語。'</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{}</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">]</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "錯誤示範"
      ],
      "metadata": {
        "id": "wx0SMpAFkmtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "error_chain = {'key': 'hello'} | summary_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "sU97E1abkjQF",
        "outputId": "88b52d5d-7dad-473f-95b6-52183c3216a9",
        "collapsed": true
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-5482ab8bdfcc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0merror_chain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'hello'\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0msummary_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m__ror__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mRunnableSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoerce_to_runnable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m     def pipe(\n\u001b[0m\u001b[1;32m    590\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0mothers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRunnable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOther\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOther\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m   5835\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnableParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5836\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5837\u001b[0;31m         msg = (\n\u001b[0m\u001b[1;32m   5838\u001b[0m             \u001b[0;34mf\"Expected a Runnable, callable or dict.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5839\u001b[0m             \u001b[0;34mf\"Instead got an unsupported type: {type(thing)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps__, **kwargs)\u001b[0m\n\u001b[1;32m   3537\u001b[0m             \u001b[0msteps__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcoerce_to_runnable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3538\u001b[0m         )\n\u001b[0;32m-> 3539\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3540\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_lc_serializable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3537\u001b[0m             \u001b[0msteps__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcoerce_to_runnable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3538\u001b[0m         )\n\u001b[0;32m-> 3539\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3540\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_lc_serializable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m   5841\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5843\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5844\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5845\u001b[0m def chain(\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-2 LCEL 實用功能"
      ],
      "metadata": {
        "id": "cz50acdYNr6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 串接可呼叫物件"
      ],
      "metadata": {
        "id": "tB0r-qDKNQ2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import attrgetter\n",
        "get_messages = attrgetter('messages')\n",
        "from operator import itemgetter\n",
        "get_first_item = itemgetter(0)"
      ],
      "metadata": {
        "id": "Kh8p9xsYwxFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = (summary_chain\n",
        "           | get_messages\n",
        "           | get_first_item\n",
        "           | str_parser)\n",
        "summary.invoke({'city': '大阪'})"
      ],
      "metadata": {
        "id": "xIyzLfxHwygT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用 RunnablePassthrough\n",
        "\n",
        "https://python.langchain.com/v0.1/docs/expression_language/primitives/passthrough/\n"
      ],
      "metadata": {
        "id": "qXq9YHOwNUc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "runnable = RunnableParallel(\n",
        "    passed=RunnablePassthrough(),\n",
        "    modified=lambda x: x[\"num\"] + 1,\n",
        ")\n",
        "\n",
        "runnable.invoke({\"num\": 1})"
      ],
      "metadata": {
        "id": "kKYi9y5-yUFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RunnableBinding"
      ],
      "metadata": {
        "id": "1muHzzOcWbdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "指定額外參數(Ex: bind(stop=[]))"
      ],
      "metadata": {
        "id": "oZIJGYL4YEx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = ({\"city\": RunnablePassthrough()}\n",
        "         | prompt.bind()\n",
        "         | chat_model.bind(stop=[\"台灣\",\"臺灣\"])\n",
        "         | str_parser)\n",
        "print(chain.invoke(\"台北\"))"
      ],
      "metadata": {
        "id": "cTwlpAPnYJYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI function_calling"
      ],
      "metadata": {
        "id": "GblY0YqGX6qG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "class Search(BaseModel):\n",
        "    \"\"\"網路搜尋工具\"\"\"\n",
        "    search_input: str = Field(description=\"應該要搜尋的關鍵字\")"
      ],
      "metadata": {
        "id": "Pu6yMiM2ltR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = chat_model.bind_tools([Search])\n",
        "pprint(model.kwargs[\"tools\"])"
      ],
      "metadata": {
        "id": "Km0_FRnnpZsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate.from_template(\"{city}位於哪個國家?\")\n",
        "chain = ({\"city\": RunnablePassthrough()}\n",
        "         | prompt\n",
        "         | model)\n",
        "pprint(chain.invoke(\"台北\").tool_calls)"
      ],
      "metadata": {
        "id": "4El7wgaudquX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
        "tools_parser = JsonOutputToolsParser()"
      ],
      "metadata": {
        "id": "Xz0k8IgMYrDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chain = ({\"city\": RunnablePassthrough()}\n",
        "         | prompt\n",
        "         | model\n",
        "         | tools_parser)\n",
        "pprint(chain.invoke(\"台北\"))"
      ],
      "metadata": {
        "id": "JiracWimlwc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model.invoke(chain.invoke(\"台北\"))"
      ],
      "metadata": {
        "id": "4n1E0GZLQ4Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 分支與合併"
      ],
      "metadata": {
        "id": "2VeMShb9VP8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "person_template = ChatPromptTemplate.from_template(\n",
        "    \"是誰發明{invention}？\")\n",
        "country_template = ChatPromptTemplate.from_template(\n",
        "    \"{person}來自哪個國家？\")\n",
        "\n",
        "person_chain = ({\"invention\": RunnablePassthrough()}\n",
        "              | person_template\n",
        "              | chat_model\n",
        "              | str_parser)\n",
        "\n"
      ],
      "metadata": {
        "id": "sO9ByuR5aX7r"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "person_chain.invoke(\"珍珠奶茶\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3kHDk8QzbgDs",
        "outputId": "cd20c466-8749-4a1f-ffc3-5c73ff3eddeb"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'珍珠奶茶最初是在台灣發明的，由台灣的一家茶館創始人陳三元於1980年代初創造。珍珠奶茶後來在台灣迅速流行開來，並傳播到世界各地。现在，珍珠奶茶已成為全球流行的飲料之一。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_chain = {\"person\": person_chain} | country_template"
      ],
      "metadata": {
        "id": "jKSMdD9MdQH4"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_chain.invoke(\"珍珠奶茶\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYOvUj4HdXX9",
        "outputId": "5bc5f409-ce89-45c5-f9e9-310c25969cd5"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='珍珠奶茶最初是在臺灣發明的。最早記錄的珍珠奶茶店為1983年開在臺北市光華商場的「珍珠奶茶店」。該飲料的起源可追溯到1980年代，當時一位臺灣小吃攤販在碰巧說話時將豆奶、糖和珍珠混合在一起，意外發現味道十分美味，因此開始製作珍珠奶茶，逐漸在臺灣流行開來。來自哪個國家？', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "person_summary_chain = (\n",
        "    {\"person\": person_chain}\n",
        "    | country_template\n",
        "    | chat_model\n",
        "    | str_parser\n",
        ")\n",
        "\n",
        "person_summary_chain.invoke(\"珍珠奶茶\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K_yasHc1bU1O",
        "outputId": "2f1c0027-f3e1-44da-b2f3-41b017299c9f"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'珍珠奶茶最初被認為是由台灣發明的。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grandalf\n",
        "person_summary_chain.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlraP-KiRbJ6",
        "outputId": "ebb06228-7000-490c-cfd4-36858e907035"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: grandalf in /usr/local/lib/python3.10/dist-packages (0.8)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from grandalf) (3.2.0)\n",
            "+-----------------------+  \n",
            "| Parallel<person>Input |  \n",
            "+-----------------------+  \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "     +-------------+       \n",
            "     | Passthrough |       \n",
            "     +-------------+       \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "  +--------------------+   \n",
            "  | ChatPromptTemplate |   \n",
            "  +--------------------+   \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "      +------------+       \n",
            "      | ChatOpenAI |       \n",
            "      +------------+       \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "   +-----------------+     \n",
            "   | StrOutputParser |     \n",
            "   +-----------------+     \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "  +--------------------+   \n",
            "  | ChatPromptTemplate |   \n",
            "  +--------------------+   \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "      +------------+       \n",
            "      | ChatOpenAI |       \n",
            "      +------------+       \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "   +-----------------+     \n",
            "   | StrOutputParser |     \n",
            "   +-----------------+     \n",
            "            *              \n",
            "            *              \n",
            "            *              \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 根據使用者語氣產生不同回答\n",
        "\n",
        "This example is adapted from\n",
        "(https://github.com/iangithub/LangChainLearnBook/blob/main/CH4/demo1/demo1/demo4-7.py)"
      ],
      "metadata": {
        "id": "VSYFpq4KM2v3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義情緒分析的提示樣板\n",
        "sentiment_analysis_prompt = PromptTemplate(\n",
        "    input_variables=[\"user_input\"],\n",
        "    template=\"根據這段話分析情緒，並僅回答 'positive' 或 'negative'：'{user_input}'\"\n",
        ")\n",
        "# 建立情緒分析的 LLMChain\n",
        "sentiment_analysis_chain = sentiment_analysis_prompt | chat_model | str_parser\n",
        "\n",
        "# 負面情緒應對的 PromptTemplate\n",
        "negative_response_prompt = PromptTemplate(\n",
        "    input_variables=[\"user_input\"],\n",
        "    template=\"使用者說了這段話：'{user_input}'。請給出一段安撫的回應。\"\n",
        ")\n",
        "negative_response_chain = negative_response_prompt | chat_model | str_parser\n",
        "\n",
        "# 正面情緒應對的 PromptTemplate\n",
        "positive_response_prompt = PromptTemplate(\n",
        "    input_variables=[\"user_input\"],\n",
        "    template=\"使用者說了這段話：'{user_input}'。請給出一段正向互動的回應。\"\n",
        ")\n",
        "positive_response_chain = positive_response_prompt | chat_model | str_parser\n",
        "\n",
        "\n",
        "def execute_conditional_chain(user_input):\n",
        "    # 第一步：使用 LLM 來分析情緒\n",
        "    sentiment_result = sentiment_analysis_chain.invoke({\"user_input\": user_input})\n",
        "\n",
        "    # 第二步：根據情緒結果選擇要執行的chain\n",
        "    if sentiment_result.strip().lower() == \"negative\":\n",
        "        # 如果情緒為負面，執行負面應對chain\n",
        "        return negative_response_chain.invoke({\"user_input\": user_input})\n",
        "    else:\n",
        "        # 如果情緒為正面，執行正面應對鏈結\n",
        "        return positive_response_chain.invoke({\"user_input\": user_input})\n",
        "\n"
      ],
      "metadata": {
        "id": "IyJEFtQ9MZI7"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 執行 Conditional Chain\n",
        "execute_conditional_chain(\"我對於你們的服務感到非常滿意，服務人員很用心，環境也很整潔。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "vK0VG0yceqT1",
        "outputId": "1d19c701-6363-4b2a-8a3b-437119b4392f"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'謝謝您的肯定和讚美！我們非常高興您對我們的服務感到滿意。我們將繼續努力，提供更好的服務和環境給您，希望您下次再來光臨。感謝您的支持！如果您有任何建議或意見，都歡迎告訴我們，讓我們能更進一步提升服務品質。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "execute_conditional_chain(\"你的產品怎麼這麼貴? 可以給一些折扣嗎?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "HxXgPAY_esPV",
        "outputId": "799ad8b1-f81d-4bf0-8579-544561985038"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'非常抱歉您覺得我們的產品價格較高。我們堅持使用高品質的材料和生產工藝，確保產品的品質和耐用性。不過我們也會不定期舉辦促銷活動或提供折扣碼，讓顧客可以享有更優惠的價格。請您留下您的聯絡方式，我們會定期通知您我們的優惠活動。感謝您的支持和理解。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 零污染計畫書Chain\n",
        "\n",
        "https://colab.research.google.com/drive/1YTT7-4ezZdhWVK3eJ2fo7qQHQD9r6V1q?usp=sharing"
      ],
      "metadata": {
        "id": "JYFpA98lGgh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "json_parser = JsonOutputParser()\n",
        "format_instructions = json_parser.get_format_instructions()"
      ],
      "metadata": {
        "id": "-UvYRbk5QGNN"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model = ChatOpenAI(model='gpt-4o-mini')"
      ],
      "metadata": {
        "id": "Dz8c189Lrvkf"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 制定提示模板\n",
        "prompt1 = ChatPromptTemplate.from_template(\n",
        "    \"請根據{attribute}特性，推薦一種環保的再生能源。請僅提供能源的名稱：\"\n",
        ")\n",
        "prompt2 = ChatPromptTemplate.from_template(\n",
        "    \"在永續發展中，{energy}能源通常用於製造哪種材料？請僅提供能源材料的名稱：\"\n",
        "    \"{format_instructions}\"\n",
        ")\n",
        "prompt3 = ChatPromptTemplate.from_template(\n",
        "    \"假設每個國家的能源發展是相等的，哪個國家使用{energy}能源可以做得最好？\"\n",
        "    \"請僅提供國家/地區名稱：\"\n",
        ")\n",
        "prompt4 = ChatPromptTemplate.from_template(\n",
        "    \"請結合{material}和{country}，描述一個環境友善的未來生活場景。\"\n",
        ")\n",
        "\n",
        "prompt2 = prompt2.partial(format_instructions=format_instructions)\n",
        "# 模型串输出模板\n",
        "model_parser = chat_model | str_parser\n",
        "\n",
        "# 能源生成鏈\n",
        "energy_generator = (\n",
        "    {\"attribute\": RunnablePassthrough()}\n",
        "    | prompt1\n",
        "    | {\"energy\": model_parser}\n",
        ")\n",
        "\n",
        "# 能源材料\n",
        "energy_to_material = prompt2 | chat_model | json_parser\n",
        "\n",
        "# 能源使用做得最好的國家\n",
        "material_to_country = prompt3 | model_parser\n",
        "\n",
        "# 结合以上\n",
        "question_generator = (\n",
        "    energy_generator\n",
        "    | {\"material\": energy_to_material,\n",
        "       \"country\": material_to_country}\n",
        "    | prompt4\n",
        ")"
      ],
      "metadata": {
        "id": "iGHxd_0NaduL"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = question_generator.invoke(\"零污染\")\n",
        "print(f\"最終產生的問題：{prompt.messages[0].content}\\n\\n\"\n",
        "    \"----------------------\\n\"\n",
        "    f\"AI 回答結果：{chat_model.invoke(prompt).content}\")"
      ],
      "metadata": {
        "id": "fs9pG7kvaiyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d69a657-c37d-478d-9308-18ce45d59477"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終產生的問題：請結合{'energy_material': '氫氣'}和日本，描述一個環境友善的未來生活場景。\n",
            "\n",
            "----------------------\n",
            "AI 回答結果：在不遠的未來，日本的城市景觀已經徹底改變，成為一個環境友善、可持續發展的模範。這個場景中，氫氣被廣泛應用，成為日常生活中不可或缺的一部分。\n",
            "\n",
            "在繁忙的東京街頭，人們騎著電動氫氣摩托車，安靜且無污染，穿梭於高樓大廈之間。街道兩旁，綠色植物爬上建築物的外牆，創造出垂直花園，這些植物不僅美化了環境，還能通過光合作用吸收二氧化碳。\n",
            "\n",
            "早晨，市民們在社區的氫氣充電站為自己的車輛補充氫燃料，這些站點均由可再生能源供電，如太陽能和風能。充電站旁邊是小型氫氣咖啡館，客人們享用用氫氣加熱的飲品，無需擔心二氧化碳排放。\n",
            "\n",
            "在這個未來的社會中，房屋都裝備了氫氣燃料電池系統，提供家庭所需的電力與熱能。每個小區都有社區花園和共享農田，居民們利用氫氣供應的能量來進行水耕種植，生產新鮮的有機蔬菜，進一步減少碳足跡。\n",
            "\n",
            "晚上，城市的燈光由氫燃料電池驅動，柔和而不刺眼，不再有傳統街燈的異味和污染。人們聚集在公園中，享受著清新的空氣和乾淨的環境，孩子們在操場上玩耍，父母們則悠閒地聊天，神情愉悅。\n",
            "\n",
            "這樣的場景體現了日本在氫氣技術上的前瞻性應用，不僅提升了生活品質，也帶領社會邁向一個更加環保的未來。透過氫氣的普及使用，日本正逐步實現2050年碳中和的目標，為全球可持續發展樹立榜樣。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grandalf\n",
        "question_generator.get_graph().print_ascii()"
      ],
      "metadata": {
        "id": "nanKlXUQfufL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-3 LCEL 函式應用與分支合併"
      ],
      "metadata": {
        "id": "gIHrNMUUMZZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RunnableLambda"
      ],
      "metadata": {
        "id": "OejhtwKgMgKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda"
      ],
      "metadata": {
        "id": "dP_cYOJiMbTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def commodity(food):\n",
        "    # 定義每個商店的商品和價格\n",
        "    items = {\n",
        "        \"熱狗\": 50,\n",
        "        \"漢堡\": 70,\n",
        "        \"披薩\": 100}\n",
        "    item = items.get(food)\n",
        "    print(f\"{food}價格：{item}\")\n",
        "    return {\"price\": item}"
      ],
      "metadata": {
        "id": "Paa50mLIMi4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food=RunnableLambda(commodity)\n",
        "food.invoke(\"披薩\")"
      ],
      "metadata": {
        "id": "YaREXYXMMjlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"我選擇的商品要多少錢？\"\n",
        "                        \"數量{number}價錢{price}\")\n",
        "chain = (\n",
        "    {\n",
        "        'price':itemgetter(\"food\") | RunnableLambda(commodity),\n",
        "        'number':itemgetter(\"number\")\n",
        "    }\n",
        "    | prompt\n",
        "    | chat_model\n",
        "    | str_parser\n",
        ")\n",
        "print(chain.invoke({\"food\":\"漢堡\", \"number\":\"101\"}))"
      ],
      "metadata": {
        "id": "cKwb4PjUMlCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RunnableBranch"
      ],
      "metadata": {
        "id": "BQSCqVsnMoRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    PromptTemplate.from_template(\n",
        "        \"根據使用者問題作回答, 將問題分為'要求命令'或是'查詢答案'。\\n\"\n",
        "        \"<問題>\\n{question}\\n</問題>\\n\"\n",
        "        \"分類:\"\"\"\n",
        "    )\n",
        "    | chat_model\n",
        "    | str_parser\n",
        ")"
      ],
      "metadata": {
        "id": "dxDTDWZjMmdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.invoke({\"question\": \"立刻使用 Google 搜尋台積電股票\"}))\n",
        "print(chain.invoke({\"question\": \"告訴我什麼是極光\"}))"
      ],
      "metadata": {
        "id": "6tetbozPMqOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "order_chain = (\n",
        "    PromptTemplate.from_template(\n",
        "        \"你不會思考只根據命令做回應, 每次回答開頭都以 '是的, 主人' \"\n",
        "        \"回覆命令\\n\"\n",
        "        \"問題: {question}\\n\"\n",
        "        \"回覆:\"\n",
        "    )\n",
        "    | chat_model\n",
        ")\n",
        "ask_chain = (\n",
        "    PromptTemplate.from_template(\n",
        "        \"你只能回答知識性相關問題, 任何要求命令不會照做也不會回答,\"\n",
        "        \"每次回答開頭都以 '根據我的知識' 回覆命令\\n\"\n",
        "        \"問題: {question}\"\n",
        "        \"回覆:\"\n",
        "    )\n",
        "    | chat_model\n",
        ")\n",
        "defult_chain = (\n",
        "    PromptTemplate.from_template(\n",
        "        \"請回答問題:\\n\"\n",
        "        \"問題: {question}\\n\"\n",
        "        \"回覆:\"\n",
        "    )\n",
        "    | chat_model\n",
        ")"
      ],
      "metadata": {
        "id": "F0mV0yvHMreq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **自訂命令判斷function**"
      ],
      "metadata": {
        "id": "sw5gE8dYMt-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def route(info):\n",
        "    if \"查詢答案\" in info[\"topic\"]:\n",
        "        return ask_chain\n",
        "    elif \"要求命令\" in info[\"topic\"]:\n",
        "        return order_chain\n",
        "    else:\n",
        "        return defult_chain"
      ],
      "metadata": {
        "id": "5XrM90B9MuVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "full_chain = ({\"topic\": chain, \"question\": lambda x: x[\"question\"]}\n",
        "             | RunnableLambda(route)\n",
        "             | str_parser)"
      ],
      "metadata": {
        "id": "3yJM9RazMvhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(full_chain.invoke({\"question\": \"去幫我買東西\"}))\n",
        "print('- '*10)\n",
        "print(full_chain.invoke({\"question\": \"北極圈是在緯度多少以上？\"}))"
      ],
      "metadata": {
        "id": "m32gW0oHMxrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用 RunnableBranch"
      ],
      "metadata": {
        "id": "OQHdH2UQMzUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableBranch\n",
        "\n",
        "branch = RunnableBranch(\n",
        "    (lambda x: \"查詢答案\" in x[\"topic\"], ask_chain),\n",
        "    (lambda x: \"要求命令\" in x[\"topic\"], order_chain),\n",
        "    defult_chain,\n",
        ")"
      ],
      "metadata": {
        "id": "LWIbz26YM0TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_chain = ({\"topic\": chain, \"question\": lambda x: x[\"question\"]}\n",
        "              | branch\n",
        "              | str_parser)"
      ],
      "metadata": {
        "id": "jzDPvyz7M1mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(full_chain.invoke({\"question\": \"幫我寫一篇哈利波特小說短評\"}))\n",
        "print('- '*10)\n",
        "print(full_chain.invoke({\"question\": \"台北101有多高？\"}))"
      ],
      "metadata": {
        "id": "bhxOX7qGM2OH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}