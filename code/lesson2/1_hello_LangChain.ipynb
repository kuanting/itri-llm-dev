{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Hello World\n",
        "Author: K. T. Lai <br>\n",
        "Date: 2025/1/9\n",
        "\n"
      ],
      "metadata": {
        "id": "mB7QCrz6oEba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intall LangChain"
      ],
      "metadata": {
        "id": "fIa_dAwtqyYB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAXTEq58QaK-",
        "outputId": "8e2ba182-363c-4a3a-9c77-decf7f611b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain --quiet\n",
        "!pip install langchain_openai --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 輸入 OpenAI keys (兩種方式)"
      ],
      "metadata": {
        "id": "YJ1YIG2Nq92M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用者輸入Key並存在全域變數 (Blocking)\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcocCJ-xRX9r",
        "outputId": "fecda741-1b2c-407c-ef21-a5a5f5405e39"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for OpenAI: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 從Colab中讀取並存取全域變數\n",
        "from google.colab import userdata\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "tukAaspNryZW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use ChatOpenAI"
      ],
      "metadata": {
        "id": "x-zX487br_Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "NQT7LXXNr35P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(\"Hello, world!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REQSYzRgVTXP",
        "outputId": "4533a09e-20d6-48d6-bfa3-80cd17ee5314"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 11, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'stop', 'logprobs': None}, id='run-6a31ce74-29a7-49cf-b423-29d3b43aba09-0', usage_metadata={'input_tokens': 11, 'output_tokens': 10, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ret = model.invoke(\"用繁體中文自我介紹一下\")"
      ],
      "metadata": {
        "id": "K1iyVNx6VkCQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyFB2rlCVw5Y",
        "outputId": "04d875af-d926-4ac6-ca8b-9003432f6b25"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "你好！我是AI助手，專門用來回答問題和提供各類資訊。我能夠協助你解決問題、提供建議或是進行各種主題的討論。如果你有任何疑問或需要幫助的地方，隨時可以問我！很高興認識你！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming Mode (串流模式)"
      ],
      "metadata": {
        "id": "aFwr30SVXiq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = model.stream(\"請介紹LangChain\")\n",
        "for chunk in chunks:\n",
        "    print(chunk.content, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PpwYEONXgas",
        "outputId": "a9e0425f-b4f2-4697-c621-c8b196dcbfaf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain是一個開源框架，旨在幫助開發者構建以語言模型為基礎的應用程序。其核心理念是將大型語言模型（LLMs）與其他資源（如API、數據庫和網絡服務）結合起來，以創建功能強大的應用。\n",
            "\n",
            "LangChain的主要特性包括：\n",
            "\n",
            "1. **鏈接組件**：LangChain允許開發者將不同的組件（如輸入處理、上下文管理、結果生成等）鏈接在一起，這樣可以更靈活地構建應用邏輯。\n",
            "\n",
            "2. **多種來源的整合**：LangChain支持多種不同來源的數據，如文本檔案、API響應、數據庫查詢等，使得開發者可以輕鬆地集成和處理不同的數據來源。\n",
            "\n",
            "3. **上下文管理**：LangChain提供了一些工具來管理上下文，確保語言模型在生成回應時能夠考慮到先前的對話內容或其他相關信息。\n",
            "\n",
            "4. **擴展性**：開發者可以根據自己的需求擴展LangChain，添加自定義的功能和邏輯，以滿足特定的使用案例。\n",
            "\n",
            "5. **多種語言模型的支持**：LangChain支持多種不同的語言模型，這意味著開發者可以根據需求選擇最合適的模型來實現其應用。\n",
            "\n",
            "LangChain的目的是簡化開發過程中與語言模型互動的複雜性，並提供強大的工具來創建更智能、更具交互性的應用程序。這使得它在自然語言處理、對話系統、自動化和數據分析等領域中具有廣泛的應用潛力。"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cache(快取) - 儲存以回答過的問題"
      ],
      "metadata": {
        "id": "zb65t48nYoM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65W7-5FqlEnF",
        "outputId": "3850d022-4e2a-4baf-94eb-6a5f05386f6d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.globals import set_llm_cache\n",
        "from langchain_community.cache import InMemoryCache\n",
        "\n",
        "set_llm_cache(InMemoryCache())"
      ],
      "metadata": {
        "id": "ACJYWVk-ZLGz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cache_model = ChatOpenAI(model=\"gpt-4o-mini\", cache=True)"
      ],
      "metadata": {
        "id": "DaVl8lejYnNL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 比較(有/無)Cache執行時間"
      ],
      "metadata": {
        "id": "jjP6YP-2lWTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cache_model.invoke(\"請說個AI笑話\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbHgVzMPlP2m",
        "outputId": "96486a3f-39c9-41b5-ab82-09475848fbc7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 26.8 ms, sys: 898 µs, total: 27.7 ms\n",
            "Wall time: 914 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='當然可以！這是一個AI相關的笑話：\\n\\n為什麼人工智能從來不需要運動？\\n\\n因為它們已經有好的演算法來「運行」！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 13, 'total_tokens': 55, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-b5520cef-c498-4598-a6b5-0aeaae834279-0', usage_metadata={'input_tokens': 13, 'output_tokens': 42, 'total_tokens': 55, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cache_model.invoke(\"請說個AI笑話\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zVrSKq8mGqi",
        "outputId": "561b1d5c-17b7-41f3-a9ed-efd9c90c23a5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 802 µs, sys: 0 ns, total: 802 µs\n",
            "Wall time: 809 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='當然可以！這是一個AI相關的笑話：\\n\\n為什麼人工智能從來不需要運動？\\n\\n因為它們已經有好的演算法來「運行」！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 13, 'total_tokens': 55, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-b5520cef-c498-4598-a6b5-0aeaae834279-0', usage_metadata={'input_tokens': 13, 'output_tokens': 42, 'total_tokens': 55, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 計算模型使用費用"
      ],
      "metadata": {
        "id": "HYqTSMDomuGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "    result= cache_model.invoke(\"簡單介紹LangChain\")\n",
        "    print(result.content)\n",
        "    print(result.response_metadata['token_usage'])\n",
        "    print(result.id)\n",
        "    print(cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ96yjCwmxHa",
        "outputId": "9442b513-b21f-45e6-eed2-947d876220e2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain 是一個開源框架，旨在幫助開發者構建應用程序，利用大型語言模型（如 OpenAI 的 GPT 系列）進行文本生成、對話系統、數據分析等任務。它的設計重點是使開發者能夠更輕鬆地集成和部署這類模型，並提供了一些有用的工具和功能。\n",
            "\n",
            "LangChain 的主要特點包括：\n",
            "\n",
            "1. **模組化設計**：LangChain 提供了不同的組件，例如鏈（chains）、記憶（memory）、代理（agents）等，開發者可以根據需求組合這些組件來實現複雜的應用。\n",
            "\n",
            "2. **支持多種語言模型**：除了 OpenAI 的模型，LangChain 還支持其他流行的語言模型，這使得用戶可以根據需求選擇最合適的模型。\n",
            "\n",
            "3. **上下文管理**：LangChain 能夠管理上下文信息，使模型能夠記住之前的對話或資訊，從而提升交互的連貫性。\n",
            "\n",
            "4. **與外部數據源集成**：LangChain 可以與各種外部數據源（如 API、數據庫等）集成，讓模型能夠在有實時數據的情況下進行推理和生成。\n",
            "\n",
            "5. **對話流程設計**：開發者可以使用 LangChain 設計複雜的對話流程，並為用戶提供更加自然和流暢的交互體驗。\n",
            "\n",
            "總之，LangChain 是一個強大且靈活的工具，適合希望充分利用大型語言模型功能的開發者。\n",
            "{'completion_tokens': 389, 'prompt_tokens': 12, 'total_tokens': 401, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n",
            "run-24e924ce-d205-4531-bc24-e5b5a3a1bc57-0\n",
            "Tokens Used: 401\n",
            "\tPrompt Tokens: 12\n",
            "\t\tPrompt Tokens Cached: 0\n",
            "\tCompletion Tokens: 389\n",
            "\t\tReasoning Tokens: 0\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.00023519999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Google Gemini\n",
        "\n",
        "[Reference](https://python.langchain.com/docs/integrations/chat/google_generative_ai/)\n",
        "\n",
        "[Gemini Pricing](https://ai.google.dev/pricing?hl=zh-tw#1_5flash)"
      ],
      "metadata": {
        "id": "-wpQAEMcCEVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6yRNN4VD8Zk",
        "outputId": "4e2c8827-c34f-47dc-cc75-072402e60893"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "id": "b763gDWGEXfS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "82wkkw4OnzvN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"說個關於AI的笑話\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHH1-a05DTAj",
        "outputId": "49a3246b-fab4-4b58-f97d-d7ec2d98b5f2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='為什麼AI過馬路？\\n\\n因為它被程式設計成要到達另一邊！', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-9acba676-7774-4b36-9d74-7f8457cac832-0', usage_metadata={'input_tokens': 7, 'output_tokens': 19, 'total_tokens': 26, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Safety Settings"
      ],
      "metadata": {
        "id": "X5hTRifEJ3Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import (\n",
        "    ChatGoogleGenerativeAI,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        ")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-pro\",\n",
        "    safety_settings={\n",
        "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "dvZJyfRsJnd3"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}